<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Background · GRAPE.jl</title><meta name="title" content="Background · GRAPE.jl"/><meta property="og:title" content="Background · GRAPE.jl"/><meta property="twitter:title" content="Background · GRAPE.jl"/><meta name="description" content="Documentation for GRAPE.jl."/><meta property="og:description" content="Documentation for GRAPE.jl."/><meta property="twitter:description" content="Documentation for GRAPE.jl."/><meta property="og:url" content="https://juliaquantumcontrol.github.io/GRAPE.jl/background/"/><meta property="twitter:url" content="https://juliaquantumcontrol.github.io/GRAPE.jl/background/"/><link rel="canonical" href="https://juliaquantumcontrol.github.io/GRAPE.jl/background/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/citations.css" rel="stylesheet" type="text/css"/><link href="https://juliaquantumcontrol.github.io/QuantumControl.jl/dev/assets/topbar/topbar.css" rel="stylesheet" type="text/css"/><script src="https://juliaquantumcontrol.github.io/QuantumControl.jl/dev/assets/topbar/topbar.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">GRAPE.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../usage/">Usage</a></li><li class="is-active"><a class="tocitem" href>Background</a><ul class="internal"><li><a class="tocitem" href="#Prerequisite:-Wirtinger-derivatives-and-matrix-calculus"><span>Prerequisite: Wirtinger derivatives and matrix calculus</span></a></li><li><a class="tocitem" href="#Gradients-for-final-time-functionals"><span>Gradients for final-time functionals</span></a></li><li><a class="tocitem" href="#Derivative-of-the-time-evolution-operator"><span>Derivative of the time-evolution operator</span></a></li><li><a class="tocitem" href="#GRAPE-scheme"><span>GRAPE scheme</span></a></li><li><a class="tocitem" href="#Semi-automatic-differentiation"><span>Semi-automatic differentiation</span></a></li><li><a class="tocitem" href="#Running-costs"><span>Running costs</span></a></li><li><a class="tocitem" href="#Optimizers"><span>Optimizers</span></a></li></ul></li><li><a class="tocitem" href="../api/">API</a></li><li><a class="tocitem" href="../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Background</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Background</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaQuantumControl/GRAPE.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaQuantumControl/GRAPE.jl/blob/master/docs/src/background.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Background"><a class="docs-heading-anchor" href="#Background">Background</a><a id="Background-1"></a><a class="docs-heading-anchor-permalink" href="#Background" title="Permalink"></a></h1><p>The GRAPE methods minimizes an optimization functional of the form</p><p class="math-container">\[\begin{equation}\label{eq:grape-functional}
J(\{ϵ_l(t)\})
    = J_T(\{|Ψ_k(T)⟩\})
    + λ_a \, \underbrace{∑_l \int_{0}^{T} g_a(ϵ_l(t)) \, dt}_{=J_a(\{ϵ_l(t)\})}
    + λ_b \, \underbrace{∑_k \int_{0}^{T} g_b(|Ψ_k(t)⟩) \, dt}_{=J_b(\{|Ψ_k(t)⟩\})}\,,
\end{equation}\]</p><p>where <span>$\{ϵ_l(t)\}$</span> is a set of <a href="https://juliaquantumcontrol.github.io/QuantumControl.jl/dev/glossary/#Control-Function">control functions</a> defined between the initial time <span>$t=0$</span> and the final time <span>$t=T$</span>, and <span>$\{|Ψ_k(t)⟩\}$</span> is a set of <a href="https://juliaquantumcontrol.github.io/QuantumControl.jl/dev/api/reference/#QuantumControl.Trajectory">&quot;trajectories&quot;</a> evolving from a set of initial states <span>$\{|\Psi_k(t=0)⟩\}$</span> under the controls <span>$\{ϵ_l(t)\}$</span>. The primary focus is on the final-time functional <span>$J_T$</span>, but running costs <span>$J_a$</span> (weighted by <span>$λ_a$</span>) may be included to penalize certain features of the control field. In principle, a state-dependent running cost <span>$J_b$</span> weighted by <span>$λ_b$</span> can also be included (and will be discussed below), although this is currently not fully implemented in <code>GRAPE.jl</code>.</p><p>The defining assumptions of the GRAPE method are</p><ol><li><p>The control fields <span>$\epsilon_l(t)$</span> are piecewise-constant on the <span>$N_T$</span> intervals of a time grid <span>$t_0 = 0, t_1, \dots t_{N_T} = T$</span>. That is, we have a vector of pulse values with elements <span>$\epsilon_{nl}$</span>. We use the double-index <code>nl</code>, for the value of the <span>$l$</span>&#39;th control field on the <span>$n$</span>&#39;th interval of the time grid.</p></li><li><p>The states <span>$\ket{\Psi_k(t)}$</span> evolve under an equation of motion of the form</p></li></ol><p class="math-container">\[\begin{equation}\label{eq:tdse}
    i \hbar \frac{\partial \ket{\Psi_k(t)}}{\partial t} = \hat{H}_k(\{\epsilon_l(t)\}) \ket{\Psi_k(t)}\,,
\end{equation}\]</p><p>with <span>$\hbar = 1$</span>.</p><p>This includes the Schrödinger equation, but also the Liouville equation for open quantum systems. In the latter case <span>$\ket{\Psi_k}$</span> is replaced by a vectorized density matrix, and <span>$\hat{H}_k$</span> is replaced by a Liouvillian (super-) operator describing the dynamics of the <span>$k$</span>&#39;th trajectory. The crucial point is that Eq. \eqref{eq:tdse} can be solved analytically within each time interval as</p><p class="math-container">\[\begin{equation}\label{eq:time-evolution-op}
    \def\ii{\mathrm{i}}
    \ket{\Psi_k(t_{n+1})} = \underbrace{\exp\left[-\ii \hat{H}_{kn} dt_n \right]}_{=\hat{U}^{(k)}_{n}} \ket{\Psi_k(t_n)}\,,
\end{equation}\]</p><p>where <span>$\hat{H}_{kn} = \hat{H}_k(\{\epsilon_{nl}\})$</span> is <span>$\hat{H}_k(\{\epsilon_l(t)\})$</span> evaluated at the midpoint of the <span>$n$</span>&#39;th interval (respectively at <span>$t=0$</span> and <span>$t=T$</span> for <span>$n=1$</span> and <span>$n=N_T$</span>), and with the time step <span>$dt_n = (t_n - t_{n-1})$</span>.</p><p>These two assumptions allow to analytically derive the gradient <span>$(\nabla J)_{nl} \equiv \frac{\partial J}{\partial \epsilon_{nl}}$</span>. The initial derivation of GRAPE by <a href="../references/#KhanejaJMR2005">Khaneja <em>et al.</em> [1]</a> focuses on a final-time functional <span>$J_T$</span> that depends of the overlap of each forward-propagated <span>$|\Psi_k(T)⟩$</span> with a target state <span>$|\Psi^{\text{tgt}}_k(T)⟩$</span> and updates the pulse values <span>$\epsilon_{nl}$</span> directly in the direction of the negative gradient. Improving on this, <a href="../references/#FouquieresJMR2011">de Fouquières <em>et al.</em> [3]</a> showed that using a quasi-Newton method to update the pulses based on the gradient information leads to a dramatic improvement in convergence and stability. Furthermore, <a href="../references/#GoodwinJCP2015">Goodwin and Kuprov [4]</a> improved on the precision of evaluating the gradient of a local time evolution operator, which is a critical step in the GRAPE scheme. Finally, <a href="../references/#GoerzQ2022">Goerz <em>et al.</em> [5]</a> generalized GRAPE to arbitrary functionals of the form \eqref{eq:grape-functional}, bridging the gap to automatic differentiation techniques [<a href="../references/#LeungPRA2017">6</a>–<a href="../references/#AbdelhafezPRA2020">8</a>] by introducing the technique of &quot;semi-automatic differentiation&quot;. This most general derivation is the basis for the implementation in <code>GRAPE.jl</code>.</p><a id="tmidr"/><div class="admonition is-success" id="Too-Many-Indices;-Didn&#39;t-Read-(TMIDR)-4fdd1d0d3e6953a"><header class="admonition-header">Too Many Indices; Didn&#39;t Read (TMIDR)<a class="admonition-anchor" href="#Too-Many-Indices;-Didn&#39;t-Read-(TMIDR)-4fdd1d0d3e6953a" title="Permalink"></a></header><div class="admonition-body"><p>Below, we derive the GRAPE scheme here in full generality. This implies keeping track of a lot of indices:</p><ul><li><span>$k$</span>: the index over the different <a href="https://juliaquantumcontrol.github.io/QuantumControl.jl/dev/api/reference/#QuantumControl.Trajectory">trajectories</a>, i.e. the states <span>$|\Psi_k(t)⟩$</span> whose time evolution contribute to the functional</li><li><span>$l$</span>: the index over the different <a href>control functions</a> <span>$\epsilon_l(t)$</span> that the Hamiltonian/Liouvillian may depend on</li><li><span>$n$</span>: The index over the intervals of the time grid</li></ul><p>Most equations can be simplified by not worrying about <span>$k$</span> or <span>$l$</span>: If there multiple controls, they are concatenated into a single vector of control values with a double-index <span>$nl$</span>. We really only need to keep track of <span>$n$</span>; the gradient values related to a <span>$\epsilon_{nl}$</span> with a particular <span>$l$</span> are somewhat obvioulsly obtained by using a particular <span>$\epsilon_l(t_n)$</span>. Likewise, all trajectories contribute equally to the gradients, so we just have a sum over the <span>$k$</span> index.</p><p>We can further simplify by considering only final-time functionals <span>$J_T(\{|\Psi_k(T)⟩\})$</span>. Running costs <span>$J_a(\{ϵ_l(t)\})$</span> are quite straightforward to add (just take the deriverive w.r.t. the values <span>$ϵ_{nl}$</span>), and running costs <span>$J_b(\{|Ψ_k(t)⟩\})$</span> are too complicated to consider in any kind of &quot;simplified&quot; scheme.</p><p>In essence, then, the GRAPE scheme that is implemented here can then be concisely summarized, cf. Eq. \eqref{eq:grad-at-T-U}, as</p><p class="math-container">\[\begin{equation}
\frac{\partial J_T}{\partial \epsilon_{n}}
= -2 \Re
   \underbrace{%
       \underbrace{\bigg\langle \chi(T) \bigg\vert \hat{U}_{N_T} \dots \hat{U}_{n+1} \bigg \vert}_{\equiv \bra{\chi(t_n)}\;\text{(bw. prop.)}}
       \frac{\partial \hat{U}_n}{\partial \epsilon_{n}}
   }_{\equiv \bra{\chi^\prime(t_{n-1})}}
   \underbrace{\bigg \vert \hat{U}_{n-1} \dots \hat{U}_1 \bigg\vert \Psi(t=0) \bigg\rangle}_{\equiv \ket{\Psi(t_{n-1})}\;\text{(fw. prop.)}}\,,
\end{equation}\]</p><p>with the boundary condition, cf. Eq. \eqref{eq:chi},</p><p class="math-container">\[\begin{equation}
    |\chi(T)⟩ \equiv - \frac{\partial J_T}{\partial ⟨\Psi(T)|}\,.
\end{equation}\]</p><p>The gradient-state <span>$|\chi^\prime(t_{n-1})⟩$</span> is obtained either via an expansion of <span>$\hat{U}_n$</span> <a href="#Overview-Taylor">into a Taylor series</a>, or (by default), by backward-propagating an <a href="#Overview-Schermer-Gradient">extended state <span>$|\tilde\chi(t)⟩$</span> with gradient information</a> [<a href="../references/#GoodwinJCP2015">4</a>]. The resulting scheme is illustrated in <a href="#fig-grape-scheme">Fig. 1</a>.</p></div></div><h2 id="Prerequisite:-Wirtinger-derivatives-and-matrix-calculus"><a class="docs-heading-anchor" href="#Prerequisite:-Wirtinger-derivatives-and-matrix-calculus">Prerequisite: Wirtinger derivatives and matrix calculus</a><a id="Prerequisite:-Wirtinger-derivatives-and-matrix-calculus-1"></a><a class="docs-heading-anchor-permalink" href="#Prerequisite:-Wirtinger-derivatives-and-matrix-calculus" title="Permalink"></a></h2><p>Even though we are seeking the derivative of the real-valued functional <span>$J$</span> with respect to the real-valued parameter <span>$\epsilon_{nl}$</span>, the functional still involves complex quantities via <span>$|\Psi_k(t)⟩$</span> and <span>$\hat{H}$</span> in Eq. \eqref{eq:tdse}. In order to apply the chain rule in the derivation of the gradient, we will have to clarify the notion of derivatives in the context of complex numbers, as well as derivatives with respect to vectors (&quot;matrix calculus&quot;).</p><h3 id="Derivatives-w.r.t.-complex-scalars"><a class="docs-heading-anchor" href="#Derivatives-w.r.t.-complex-scalars">Derivatives w.r.t. complex scalars</a><a id="Derivatives-w.r.t.-complex-scalars-1"></a><a class="docs-heading-anchor-permalink" href="#Derivatives-w.r.t.-complex-scalars" title="Permalink"></a></h3><p>To illustrate, let&#39;s say we introduce intermediary scalar variables <span>$z_k \in \mathbb{C}$</span> in the functional, <span>$J(\{\epsilon_{nl}\}) \rightarrow J(\{z_k(\{\epsilon_{nl}\})\})$</span>, with <span>$J, \epsilon_{nl} \in \mathbb{R}$</span>.</p><p>In principle, one must separate the <span>$z_k$</span> into real and imaginary part as independent variables, <span>$J = J(\{\Re[z_k]\}, \{\Im[z_k]\})$</span>, resulting in</p><p class="math-container">\[\begin{equation}
  \label{eq:grad_zj_real_imag}
  (\nabla J)_{nl}
  \equiv \frac{\partial J}{\partial \epsilon_{nl}}
  = \sum_k \left(
    \frac{\partial J}{\partial \Re[z_k]}
    \frac{\partial \Re[z_k]}{\partial \epsilon_{nl}}
    + \frac{\partial J}{\partial \Im[z_k]}
    \frac{\partial \Im[z_k]}{\partial \epsilon_{nl}}
    \right)\,.
\end{equation}\]</p><p>An elegant alternative is to introduce <a href="https://en.wikipedia.org/wiki/Wirtinger_derivatives">Wirtinger derivatives</a>,</p><p class="math-container">\[\begin{align}%
  \label{eq:wirtinger1}
  \frac{\partial J}{\partial z_k}
    &amp;\equiv \frac{1}{2} \left(
      \frac{\partial J}{\partial \Re[z_k]}
      -\ii \frac{\partial J}{\partial \Im[z_k]}
      \right)\,, \\
  \label{eq:wirtinger2}
  \frac{\partial J}{\partial z_k^*}
    &amp;\equiv \frac{1}{2} \left(
      \frac{\partial J}{\partial \Re[z_k]}
      +\ii \frac{\partial J}{\partial \Im[z_k]}
      \right)
    = \left(\frac{\partial J}{\partial z_k}\right)^*\,,
\end{align}\]</p><p>which instead treats <span>$z_k$</span> and the conjugate value <span>$z_k^*$</span> as independent variables, so that</p><p class="math-container">\[\begin{equation}%
  \label{eq:wirtinger_chainrule}
  \frac{\partial J}{\partial \epsilon_{nl}}
  = \sum_k \left(
    \frac{\partial J}{\partial z_k}
    \frac{\partial z_k}{\partial \epsilon_{nl}}
    + \frac{\partial J}{\partial z_k^*}
    \frac{\partial z_k^*}{\partial \epsilon_{nl}}
    \right)
  = 2 \Re \sum_k \frac{\partial J}{\partial z_k}
    \frac{\partial z_k}{\partial \epsilon_{nl}}
    \,.
\end{equation}\]</p><p>So, we have a simple chain rules, modified only by <span>$2 \Re[…]$</span>, where we can otherwise &quot;forget&quot; that <span>$z_k$</span> is a complex variable. The fact that <span>$J \in \mathbb{R}$</span> guarantees that <span>$z_k$</span> and <span>$z_k^*$</span> can only occur in such ways that we don&#39;t have to worry about having &quot;lost&quot; <span>$z_k^*$</span>.</p><p>The derivative of the complex value <span>$z_k$</span> with respect to the real value <span>$\epsilon_{nl}$</span> is defined straightforwardly as</p><p class="math-container">\[\begin{equation}
  \frac{\partial z_k}{\partial \epsilon_{nl}}
  \equiv
  \frac{\partial \Re[z_k]}{\partial \epsilon_{nl}}
  + \ii \frac{\partial \Im[z_k]}{\partial \epsilon_{nl}}\,.
\end{equation}\]</p><h3 id="Derivatives-w.r.t.-complex-vectors"><a class="docs-heading-anchor" href="#Derivatives-w.r.t.-complex-vectors">Derivatives w.r.t. complex vectors</a><a id="Derivatives-w.r.t.-complex-vectors-1"></a><a class="docs-heading-anchor-permalink" href="#Derivatives-w.r.t.-complex-vectors" title="Permalink"></a></h3><p>We can now go one step further and allow for intermediate variables that are complex <em>vectors</em> instead of scalars, <span>$J(\{\epsilon_{nl}\}) \rightarrow J(\{|\Psi_k(\{\epsilon_{nl}\})⟩\})$</span>. Taking the derivative w.r.t. a vector puts us in the domain of <a href="https://en.wikipedia.org/wiki/Matrix_calculus">matrix calculus</a>. Fundamentally, the derivative of a scalar with respect to a (column) vector is a (row) vector consisting of the derivatives of the scalar w.r.t. the components of the vector, and the derivative of a vector w.r.t. a scalar is the obvious vector of derivatives.</p><p>Usually, matrix calculus assumes real-valued vectors, but the extension to complex vectors via the Wirtinger derivatives discussed above is a relatively straightforward. The use of <a href="https://en.wikipedia.org/wiki/Bra–ket_notation">Dirac (&quot;braket&quot;) notation</a> helps tremendously here: <span>$|\Psi_k⟩$</span> describes a complex column vector, and <span>$⟨\Psi_k|$</span> describes the corresponding row vector with complex-conjugated elements. These can take the place of <span>$z_k$</span> and <span>$z_k^*$</span> in the Wirtinger derivative. Consider, e.g.,</p><p class="math-container">\[\begin{equation}\label{eq:Jsm}
J(\{|\Psi_k⟩\})
= \sum_k \vert \langle \Psi_k \vert \Psi_k^{\text{tgt}} \rangle \vert^2
= \sum_k \langle \Psi_k \vert \Psi_k^{\text{tgt}} \rangle \langle \Psi_k^{\text{tgt}} \vert \Psi_k \rangle\,,
\end{equation}\]</p><p>for a fixed set of &quot;target states&quot; <span>$|\Psi_k^{\text{tgt}}⟩$</span>.</p><p>The derivative <span>$\partial J/\partial |\Psi_k⟩$</span> is</p><p class="math-container">\[\begin{equation}\label{eq:dJ_dKet}
\frac{\partial J}{\partial |\Psi_k}⟩ = \langle \Psi_k \vert \Psi_k^{\text{tgt}} \rangle \langle\Psi_k^{\text{tgt}}\vert\,,
\end{equation}\]</p><p>in the same sense as Eq. \eqref{eq:wirtinger1}. We simply treat <span>$|\Psi_k⟩$</span> and <span>$⟨\Psi_k|$</span> as independent variables corresponding to <span>$z_k$</span> and <span>$z_k^*$</span>. Note that the result is a &quot;bra&quot;, that is, a co-state, or <em>row vector</em>. The braket notation resolves the question of <a href="https://en.wikipedia.org/wiki/Matrix_calculus#Layout_conventions">&quot;layout conventions&quot;</a> in matrix calculus in favor of the &quot;numerator layout&quot;. Consequently, we also have a well-defined derivative w.r.t. the co-state:</p><p class="math-container">\[\begin{equation}
\frac{\partial J}{\partial ⟨\Psi_k|} = \langle \Psi_k^{\text{tgt}} \vert \Psi_k \rangle \vert\Psi_k^{\text{tgt}}\rangle\,,
\end{equation}\]</p><p>which we can either get explicitly from Eq. \eqref{eq:Jsm}, differentiating w.r.t. <span>$|\Psi_k⟩$</span> as an independent parameter and changing the order of the factors, or implicitly by taking the conjugate transpose of Eq. \eqref{eq:dJ_dKet}.</p><p>For the full chain rule of a functional <span>$J(\{|\Psi_k(\{\epsilon_{nl}\})⟩\})$</span>, we thus find</p><p class="math-container">\[\begin{equation}\label{eq:grad-via-chi1}
  (\nabla J)_{nl}
  \equiv \frac{\partial J}{\partial \epsilon_{nl}}
  = 2 \Re \sum_k \left(
    \frac{\partial J}{\partial |\Psi_k⟩}
    \frac{\partial |\Psi_k⟩}{\partial \epsilon_{nl}}
  \right)\,.
\end{equation}\]</p><p>With the definition in Eq. \eqref{eq:wirtinger1}, this corresponds directly to the scalar</p><p class="math-container">\[\begin{equation}
  \frac{\partial J}{\partial \epsilon_{nl}}
  = \sum_{km} \left(
    \frac{\partial J}{\partial \Re[\Psi_{km}]}
    \frac{\partial \Re[\Psi_{km}]}{\partial \epsilon_{nl}}
    + \frac{\partial J}{\partial \Im[\Psi_{km}]}
    \frac{\partial \Im[\Psi_{km}]}{\partial \epsilon_{nl}}
  \right)\,,
\end{equation}\]</p><p>where the complex scalar <span>$\Psi_{km}$</span> is the <span>$m$</span>&#39;th element of the <span>$k$</span>&#39;th vector, and corresponds to the <span>$z_k$</span> in Eq. \eqref{eq:wirtinger_chainrule}.</p><p>In open quantum systems, where the state is described by a density matrix <span>$\hat{\rho}$</span>, it can be helpful to adopt the double-braket notation <span>$\langle\!\langle \hat{\rho}_1 \vert \hat{\rho}_2 \rangle\!\rangle \equiv \tr[\hat{\rho}_1^\dagger \hat{\rho}_2]$</span>, respectively to keep track of normal states <span>$\hat{\rho}$</span> (corresponding to <span>$|\Psi⟩$</span>) and adjoint states <span>$\hat{\rho}^\dagger$</span> (corresponding to <span>$⟨\Psi|$</span>), even when <span>$\hat{\rho}$</span> is Hermitian and thus <span>$\hat{\rho} = \hat{\rho}^\dagger$</span>. For numerical purposes, density matrices are best vectorized by concatenating the columns of <span>$\hat{\rho}$</span> into a single column vector <span>$\vec{\rho}$</span>. Thus, we do not have be concerned with a separate definition of derivatives w.r.t. density matrices.</p><h2 id="Gradients-for-final-time-functionals"><a class="docs-heading-anchor" href="#Gradients-for-final-time-functionals">Gradients for final-time functionals</a><a id="Gradients-for-final-time-functionals-1"></a><a class="docs-heading-anchor-permalink" href="#Gradients-for-final-time-functionals" title="Permalink"></a></h2><p>For simplicity, we consider a functional defined entirely at final time <span>$T$</span>, the <span>$J_T$</span> term in Eq. \eqref{eq:grape-functional}. Since <span>$J_T$</span> depends explicitly on <span>$\{|\Psi_k(T)⟩\}$</span> and only implicitly on <span>$\{\epsilon_{nl}\}$</span>, we can use the complex chain rule in Eq. \eqref{eq:grad-via-chi1}.</p><p>Further, we define a new state</p><p class="math-container">\[\begin{equation}\label{eq:chi}
|\chi_k(T)⟩ \equiv - \frac{\partial J_T}{\partial ⟨\Psi_k(T)|}
\end{equation}\]</p><p>The minus sign in this definition is arbitrary, and is intended solely to match an identical definition in <a href>Krotov&#39;s method</a>, the most direct alternative to GRAPE. Since <span>$|\chi_k(T)⟩$</span> does not depend on <span>$\epsilon_{nl}$</span>, we can pull forward the derivative <span>$\partial / \partial \epsilon_{nl}$</span> in Eq. \eqref{eq:grad-via-chi1}, writing it as</p><p class="math-container">\[\begin{equation}\label{eq:grad-at-T}
(\nabla J_T)_{nl}
= \frac{\partial J_T}{\partial \epsilon_{nl}}
= - 2 \Re \sum_k \frac{\partial}{\partial \epsilon_{nl}} \langle \chi_k(T) \vert \Psi_k(T)\rangle\,.
\end{equation}\]</p><p>We end up with the gradient of <span>$J_T$</span> being the derivative of the overlap of two states <span>$|\chi_k(T)⟩$</span> and <span>$|\Psi_k(T)⟩$</span> at final time <span>$T$</span>.</p><p>Next, we make use the assumption that the time evolution is piecewise constant, so that we can use the time evolution operator defined in Eq. \eqref{eq:time-evolution-op} to write <span>$|\Psi_k(T)⟩$</span> as the time evolution of an initial state <span>$\Psi_k(t=0)$</span>, the <code>initial_state</code> of the <span>$k$</span>&#39;th <a href="https://juliaquantumcontrol.github.io/QuantumControl.jl/dev/api/reference/#QuantumControl.Trajectory"><code>trajectory</code></a> in the <a href="https://juliaquantumcontrol.github.io/QuantumControl.jl/dev/api/reference/#QuantumControl.ControlProblem"><code>QuantumControl.ControlProblem</code></a>. That is, <span>$|\Psi_k(T)⟩ = \hat{U}^{(k)}_{N_T} \dots \hat{U}^{(k)}_1 |\Psi_k(t=0)⟩$</span> with the time evolution operator <span>$\hat{U}^{(k)}_n$</span> for the <span>$n$</span>&#39;th time interval of the time grid with <span>$N_T + 1$</span> time grid points, cf. Eq. \eqref{eq:time-evolution-op}. Plugging this into Eq. \eqref{eq:grad-at-T} immediately gives us</p><p class="math-container">\[\begin{equation}\label{eq:grad-at-T-U}
\begin{split}
\frac{\partial J_T}{\partial \epsilon_{nl}}
&amp;= -2 \Re \sum_k \frac{\partial}{\partial \epsilon_{nl}}
    \bigg\langle \chi_k(T) \bigg\vert \hat{U}_{N_T}^{(k)} \dots \hat{U}^{(k)}_n \dots \hat{U}^{(k)}_1 \bigg\vert \Psi_k(t=0) \bigg\rangle
    \\
&amp;= -2 \Re \sum_k \bigg\langle \chi_k(t_{n}) \bigg\vert \frac{\partial \hat{U}^{(k)}_n}{\partial \epsilon_{nl}} \bigg\vert \Psi_k(t_{n-1}) \bigg\rangle
\end{split}
\end{equation}\]</p><p>with <span>$|\chi_k(t_{n})⟩ = U^{\dagger (k)}_{n+1} \dots U^{\dagger(k)}_{N_T} |\chi_k(T)⟩$</span>, i.e., a backward-propagation of the state given by Eq. \eqref{eq:chi} with the adjoint Hamiltonian or Liouvillian and <span>$|\Psi_k(t_{n-1})⟩ = \hat{U}^{(k)}_{n-1}\dots \hat{U}^{(k)}_1 |\Psi_k(0)⟩$</span>, i.e., a forward-propagation of the initial state of the <span>$k$</span>&#39;th trajectory.</p><h2 id="Derivative-of-the-time-evolution-operator"><a class="docs-heading-anchor" href="#Derivative-of-the-time-evolution-operator">Derivative of the time-evolution operator</a><a id="Derivative-of-the-time-evolution-operator-1"></a><a class="docs-heading-anchor-permalink" href="#Derivative-of-the-time-evolution-operator" title="Permalink"></a></h2><p>The last missing piece for evaluating the gradient in Eq. \eqref{eq:grad-at-T-U} is the derivative of the time evolution operator <span>$\hat{U}_n^{(k)}$</span> for the current time interval <span>$n$</span>. The operator <span>$\frac{\partial \hat{U}_n^{(k)}}{\partial \epsilon_{nl}}$</span> could either act to the right, being applied to <span>$|\Psi_k(t_{n-1})⟩$</span> during the forward propagation, or it (or rather it&#39;s conjugate transpose) could act to the left, being applied to <span>$|\chi_k(t_n)⟩$</span> during the backward propagation. For reasons that will be explained later on, it is numerically more efficient to include it in the backward propagation. Thus, we are given a state <span>$|\chi_k(t_{n})⟩$</span> and must then numerically obtain the state</p><p class="math-container">\[\begin{equation}\label{eq:U-deriv}
|\chi^\prime_{kl}(t_{n-1})⟩
\equiv  \frac{\partial \hat{U}^{\dagger(k)}_n}{\partial \epsilon_{nl}} |\chi_k(t_n)⟩
= \frac{\partial}{\partial \epsilon_{nl}} \exp\left[-\ii \hat{H}^{\dagger}_{k}(\{\epsilon_{nl}\}) dt^{(-)}_n \right] |\chi_k(t_n)⟩\,.
\end{equation}\]</p><p>Note the dagger and the negative time step <span>$dt^{(-)}_n = (t_{n-1} - t_{n})$</span> — in lieu of changing the sign of the imaginary unit <span>$\ii$</span> — to account for the fact that we are doing a backward-propagation, cf. the corresponding forward-propagation in Eq. \eqref{eq:time-evolution-op}. Of course, for a standard Schrödinger equation, <span>$\hat{H}_{kn}^\dagger = \hat{H}_{kn}$</span>, and then the negative time step is the only difference between backward and forward propagation; but, in general, we also allow for non-Hermitian Hamiltonians or Liouvillians where it is important to use the correct (adjoint) operator.</p><p>Thus, Eq. \eqref{eq:grad-at-T-U} turns into</p><p class="math-container">\[\begin{equation}\label{eq:grad-via-chi-prime}
\frac{\partial J_T}{\partial \epsilon_{nl}}
= -2 \Re \sum_k \bigg \langle \chi^\prime_{kl}(t_{n-1}) \bigg\vert \Psi_k(t_{n-1}) \bigg \rangle\,.
\end{equation}\]</p><p>Or, equivalently, if we had let <span>$\frac{\partial \hat{U}_n^{(k)}}{\partial \epsilon_{nl}}$</span> act to the right,</p><p class="math-container">\[\begin{equation}
\frac{\partial J_T}{\partial \epsilon_{nl}}
= -2 \Re \sum_k \bigg \langle \chi_{kl}(t_{n}) \bigg\vert \Psi^{\prime}_k(t_{n}) \bigg \rangle\,.
\end{equation}\]</p><p>with <span>$|\Psi^{\prime}_k(t_{n})⟩ \equiv  \frac{\partial \hat{U}^{(k)}_n}{\partial \epsilon_{nl}} |\Psi_k(t_{n-1})⟩$</span>.</p><h3 id="Overview-Taylor"><a class="docs-heading-anchor" href="#Overview-Taylor">Taylor expansion</a><a id="Overview-Taylor-1"></a><a class="docs-heading-anchor-permalink" href="#Overview-Taylor" title="Permalink"></a></h3><p>There are several possibilities for evaluating Eq. \eqref{eq:U-deriv}. One method is to expand the exponential into a Taylor series [<a href="../references/#KuprovJCP2009">2</a>, Eq. (20)]</p><p class="math-container">\[\begin{equation}\label{eq:taylor-op}
\frac{\partial \hat{U}^{\dagger(k)}_n}{\partial \epsilon_{nl}}
= \sum_{m=1}^{\infty} \frac{\left(-\ii \hat{H}^{\dagger}_{kn} dt^{(-)}_n\right)^m}{m!}
    \sum_{m^\prime=0}^{m-1}
    {\hat{H}^{\dagger}_{kn}}^{\!\!m^\prime}
    \hat{\mu}_{lkn}^{\dagger}
    {\hat{H}^{\dagger}_{kn}}^{\!\!m-m^\prime-1}
\end{equation}\]</p><p>with <span>$\hat{H}_{kn} \equiv \hat{H}_{k}(\{\epsilon_{nl}\})$</span> and <span>$\hat{\mu}_{lkn} \equiv \frac{\partial \hat{H}_{kn}}{\partial \epsilon_{nl}}$</span>.</p><p>In practice, Eq. \eqref{eq:taylor-op} is best evaluated recursively, while  being applied to  <span>$|\chi_k(t_n)⟩$</span>:</p><p class="math-container">\[\begin{equation}
\ket{\chi^\prime_{kl}(t_{n-1})} = \sum_{m=1}^{\infty} \frac{\left(-\ii \, dt_n^{(-)}\right)^m}{m!} \ket{\Phi^{(lkn)}_m}\,,
\end{equation}\]</p><p>with</p><p class="math-container">\[\begin{equation}
\begin{split}
  \ket{\Phi^{(lkn)}_1} &amp;= \hat{\mu}_{lkn}^{\dagger} \ket{\chi_k(t_n)}\,,              \\
  \ket{\Phi^{(lkn)}_m} &amp;= \hat{\mu}_{lkn}^{\dagger} {\hat{H}^{\dagger}_{kn}}^{\!\!m-1}  \ket{\chi_k(t_n)} + {\hat{H}^{\dagger}_{kn}} \ket{\Phi^{(lkn)}_{m-1}}\,.
\end{split}
\end{equation}\]</p><p>In <code>GRAPE.jl</code>, Eq. \eqref{eq:U-deriv} can be evaluated via a Taylor expansion as described above by passing <code>gradient_method=:taylor</code>, with further options to limit the maximum order <span>$m$</span>.</p><div class="admonition is-success" id="TMIDR-afbca503d0d1951"><header class="admonition-header">TMIDR<a class="admonition-anchor" href="#TMIDR-afbca503d0d1951" title="Permalink"></a></header><div class="admonition-body"><p>As in the <a href="#tmidr">general TMIDR</a>, the indices <span>$k$</span> and <span>$l$</span> are somewhat superfluous here. In addition, <span>$\hat{\mu}_{lkn} \equiv \frac{\partial \hat{H}_{kn}}{\partial \epsilon_{nl}}$</span> still depends on <span>$\epsilon_{nl}$</span> only for non-linear controls. Much more commonly, , for linear Hamiltonians of the form <span>$\hat{H} = \hat{H_0} + \epsilon(t) \hat{\mu}$</span>, <span>$\hat{\mu}$</span> is just a static <a href="https://juliaquantumcontrol.github.io/QuantumControl.jl/dev/glossary/#Control-Operator">control operator</a>. If <span>$\hat{H}$</span> is a standard Hamiltonian, and thus Hermitian, we can drop the dagger. The time gid is usually uniform, so we can drop the index <span>$n$</span> from <span>$dt$</span>. Thus, a simplified version of Eq. \eqref{eq:taylor-op} is</p><p class="math-container">\[\begin{equation}\label{eq:taylor-op-simplified}
\frac{\partial \hat{U}^{\dagger}_n}{\partial \epsilon_{n}}
= \sum_{m=1}^{\infty} \frac{\left(-\ii \hat{H}_{n} dt^{(-)}\right)^m}{m!}
    \sum_{m^\prime=0}^{m-1}
    \hat{H}_{n}^{m^\prime}
    \hat{\mu}
    {\hat{H}}_{n}^{m-m^\prime-1}\,,
\end{equation}\]</p><p>with the recursive formula</p><p class="math-container">\[\begin{equation}
\begin{split}
\ket{\chi^\prime(t_{n-1})} &amp;= \sum_{m=1}^{\infty} \frac{\left(-\ii \, dt^{(-)}\right)^m}{m!} \ket{\Phi_m}\,,\\
\ket{\Phi_1} &amp;= \hat{\mu} \ket{\chi_k(t_n)}\,,              \\
\ket{\Phi_m} &amp;= \hat{\mu} {\hat{H}_{n}}^{\!\!m-1}  \ket{\chi_k(t_n)} + {\hat{H}_{n}} \ket{\Phi_{m-1}}\,.
\end{split}
\end{equation}\]</p></div></div><p>For sufficiently small time steps,  one may consider using only the first term in the Taylor series, <span>$|\chi^\prime_{kl}(t_{n-1})⟩  \approx -\ii dt_n^{(-)} |\Phi^{(lkn)}_1⟩$</span>. That is, from Eq. \eqref{eq:grad-via-chi-prime}, we get</p><p class="math-container">\[\begin{equation}
\begin{split}
\frac{\partial J_T}{\partial \epsilon_{nl}}
&amp;\approx 2\,dt_n\,\Im \sum_k \bigg \langle \chi_{kl}(t_{n}) \bigg\vert \frac{\partial \hat{H}_{kn}}{\partial \epsilon_{nl}} \bigg\vert \Psi_k(t_{n-1}) \bigg \rangle \\
&amp;\approx 2\,dt_n\,\Im \sum_k \bigg \langle \chi_{kl}(t_{n}) \bigg\vert \frac{\partial \hat{H}_{kn}}{\partial \epsilon_{nl}} \bigg\vert \Psi_k(t_{n}) \bigg \rangle\,.
\end{split}
\end{equation}\]</p><p>This approximation of the gradient has been used historically, including in GRAPE&#39;s original formulation [<a href="../references/#KhanejaJMR2005">1</a>], also because it matches optimality conditions derived in a Lagrange-multiplier formalism [<a href="../references/#PeircePRA1988">9</a>, BorziPRA2002] that pre-dates GRAPE. The derivation via Lagrange multipliers also extends more easily to equations of motion beyond Eq. \eqref{eq:tdse} such as Gross–Pitaevskii equation [<a href="../references/#HohenesterPRA2007">10</a>, <a href="../references/#JaegerPRA2014">11</a>]. However, even though it is considered a &quot;gradient-type&quot; optimization, it is not considered to be within the scope of the <code>GRAPE</code> package (up to the ability to limit that Taylor expansion to first order). The conceptual difference is that these older methods (as well as other &quot;gradient-type&quot; <a href>Krotov&#39;s method</a>) derive optimality conditions <em>first</em> (via functional derivatives), and the add time discretization to arrive at a numerical scheme. In contrast, <code>GRAPE</code> discretizes <em>first</em>, and then obtains gradients via simple derivatives w.r.t. the pulse values <span>$\epsilon_{nl}$</span>. This concept of &quot;discretize first&quot; is <em>the</em> core concept exploited in <code>GRAPE.jl</code>.</p><p>After GRAPE&#39;s original formulation [<a href="../references/#KhanejaJMR2005">1</a>], it was quickly realized that high-precision gradients are essential for numerical stability and convergence, in particular if the gradient is then used in a quasi-Newton method [<a href="../references/#KuprovJCP2009">2</a>, <a href="../references/#FouquieresJMR2011">3</a>]. Thus, low-order Taylor expansions should be avoided in most contexts.</p><h3 id="Overview-Schermer-Gradient"><a class="docs-heading-anchor" href="#Overview-Schermer-Gradient">Shermer gradient</a><a id="Overview-Schermer-Gradient-1"></a><a class="docs-heading-anchor-permalink" href="#Overview-Schermer-Gradient" title="Permalink"></a></h3><p>With the need for gradients that are exact to machine precision…</p><h2 id="GRAPE-scheme"><a class="docs-heading-anchor" href="#GRAPE-scheme">GRAPE scheme</a><a id="GRAPE-scheme-1"></a><a class="docs-heading-anchor-permalink" href="#GRAPE-scheme" title="Permalink"></a></h2><p>This results in an efficient numerical scheme for evaluating the full gradient shown in <a href="#fig-grape-scheme">Fig. 1</a>. The scheme extends to situations where the functional is evaluated on top of <em>multiple</em> propagated states <span>$\{\vert \Psi_k(t) \rangle\}$</span> with an index <span>$k$</span>, and multiple controls <span>$\epsilon_l(t)$</span>, resulting in a vector of values <span>$\epsilon_{nl}$</span> with a double-index <span>$nl$</span>.</p><p id="fig-grape-scheme" style="text-align: center">
<a href="../fig/grape_scheme.png">
<img src="../fig/grape_scheme.png" width="100%"/>
</a>
<a href="#fig-grape-scheme">Figure 1</a>: Numerical scheme for the evaluation of the gradient in GRAPE, with semi-automatic differentiation
</p><p>Explain why the gradient generator is more efficient in the backward propagation: No need to store extended states.</p><h2 id="Semi-automatic-differentiation"><a class="docs-heading-anchor" href="#Semi-automatic-differentiation">Semi-automatic differentiation</a><a id="Semi-automatic-differentiation-1"></a><a class="docs-heading-anchor-permalink" href="#Semi-automatic-differentiation" title="Permalink"></a></h2><p>Same as GRAPE, up to definition of chi. Special cases for overlap functionals and gate functionals.</p><p>How &quot;gradients&quot; are implemented in Zygote.</p><h2 id="Running-costs"><a class="docs-heading-anchor" href="#Running-costs">Running costs</a><a id="Running-costs-1"></a><a class="docs-heading-anchor-permalink" href="#Running-costs" title="Permalink"></a></h2><h2 id="Optimizers"><a class="docs-heading-anchor" href="#Optimizers">Optimizers</a><a id="Optimizers-1"></a><a class="docs-heading-anchor-permalink" href="#Optimizers" title="Permalink"></a></h2><p>Once the gradient has been evaluated, in the original formulation of GRAPE [<a href="../references/#KhanejaJMR2005">1</a>], the values <span>$\epsilon_{nl}$</span> would then be updated by taking a step with a fixed step width <span>$\alpha$</span> in the direction of the negative gradient, to iteratively minimize the value of the optimization functional <span>$J$</span>. In practice, the gradient can also be fed into an arbitrary gradient-based optimizer, and in particular a quasi-Newton method like L-BFGS-B [<a href="../references/#ZhuATMS1997">12</a>, <a href="../references/#LBFGSB_jl">13</a>]. This results in a dramatic improvement in stability and convergence [<a href="../references/#FouquieresJMR2011">3</a>], and is assumed as the default in <code>GRAPE.jl</code>. Gradients of the time evolution operator can be evaluated to machine precision following <a href="../references/#GoodwinJCP2015">Goodwin and Kuprov [4]</a>. The GRAPE method could also be extended to a true Hessian of the optimization functional [<a href="../references/#GoodwinJCP2016">14</a>], which would be in scope for future versions of <code>GRAPE.jl</code>.</p><ul><li>gradient descent</li><li>L-BFGS-B</li><li>bounded controls</li><li><code>Optim.jl</code></li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../usage/">« Usage</a><a class="docs-footer-nextpage" href="../api/">API »</a><div class="flexbox-break"></div><p class="footer-message"><a href="https://github.com/JuliaQuantumControl/GRAPE.jl">GRAPE.jl</a> v0.7.5+dev docs powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.13.0 on <span class="colophon-date" title="Saturday 28 June 2025 13:31">Saturday 28 June 2025</span>. Using Julia version 1.11.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
